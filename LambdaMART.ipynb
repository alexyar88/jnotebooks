{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning-to-rank: LambdaMART gradient boosting implementation\n",
    "\n",
    "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import expit\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, query_ids = load_svmlight_file('data/l2r/train.txt', query_id=True)\n",
    "X = X.toarray()\n",
    "gc.collect()\n",
    "remove_zero_mask = ~np.all(X == 0, axis=0)\n",
    "X = X[:,remove_zero_mask].astype('float32')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(y):\n",
    "    return np.sum((2**y - 1)/ np.log2(np.arange(2, len(y) + 2)))\n",
    "\n",
    "def dcg_k(y, k=5):\n",
    "    k = min(k, len(y))\n",
    "    y = y[:k]\n",
    "    return dcg(y) \n",
    "\n",
    "def idcg_k(y, k=5):\n",
    "    y = np.sort(y)[::-1]\n",
    "    return dcg_k(y, k)\n",
    "\n",
    "def idcg(y):\n",
    "    y = np.sort(y)[::-1]\n",
    "    return dcg(y)\n",
    "\n",
    "                 \n",
    "def ndcg_k(y, k=5):\n",
    "    k = min(k, len(y))\n",
    "    idcg_val = idcg_k(y, k)\n",
    "    if idcg_val == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return dcg_k(y, k) / idcg_val\n",
    "\n",
    "def ndcg_dataset(scores, y, query_ids, k=5):\n",
    "    qids, qid_counts = np.unique(query_ids, return_counts=True)\n",
    "    qids = qids[qid_counts > 1]\n",
    "    ndcg_arr = []\n",
    "    for qid in qids:\n",
    "        mask = query_ids == qid\n",
    "        y_qid = y[mask]\n",
    "        scores_qid = scores[mask]\n",
    "        y_pred_qid = y_qid[np.argsort(scores_qid)[::-1]]\n",
    "        ndcg_arr.append(ndcg_k(y_pred_qid, k))\n",
    "    \n",
    "    return np.mean(ndcg_arr)\n",
    "\n",
    "\n",
    "class LambdaMartBoosting():\n",
    "    \n",
    "    def __init__(self, n_estimators=100, \n",
    "                 learning_rate=0.1, \n",
    "                 max_depth=5, \n",
    "                 max_features='auto',\n",
    "                 splitter='best',\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 subsample=1, \n",
    "                 verbose=10):\n",
    "        \n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.splitter = splitter\n",
    "        self.subsample = subsample\n",
    "        self.verbose = verbose\n",
    "\n",
    "                              \n",
    "    def _get_delta_ndcg(self, y_pred, ideal_dcg, i, j, k=5):\n",
    "        delta_dcg = (2**y_pred[i] - 2**y_pred[j]) * (1/np.log2(i+2) - 1/np.log2(j+2))\n",
    "        return np.abs(delta_dcg / ideal_dcg)\n",
    "            \n",
    "    \n",
    "    def _get_lambdas(self, y, query_ids, scores):\n",
    "        sigma = 1 # коэфициент наклона сигмоиды\n",
    "        lambdas = np.zeros(len(y))\n",
    "        d2c = np.zeros(len(y)) # 2-е производные для подсчета ньютоновского шага\n",
    "        all_indexes = np.arange(len(y))\n",
    "        \n",
    "        for qid in np.unique(query_ids):\n",
    "            indexes = all_indexes[query_ids == qid]\n",
    "            scores_qid = scores[indexes]\n",
    "            y_qid = y[indexes]\n",
    "            lambdas_qid = lambdas[indexes]\n",
    "            d2c_qid = d2c[indexes]\n",
    "            \n",
    "            ideal_dcg = idcg(y_qid)\n",
    "            \n",
    "            for i in range(len(y_qid)):\n",
    "                for j in range(len(y_qid)):\n",
    "                    if y_qid[i] > y_qid[j]:\n",
    "                        lambda_val = sigma * 1/(1 + np.exp(sigma * (scores_qid[i] - scores_qid[j])))\n",
    "                        delta_ndcg = self._get_delta_ndcg(y_qid, ideal_dcg, i, j)\n",
    "                        \n",
    "                        lambdas_qid[i] += lambda_val * delta_ndcg\n",
    "                        lambdas_qid[j] -= lambda_val * delta_ndcg\n",
    "                        \n",
    "                        d2c_qid[i] += lambda_val * (1 - lambda_val) * delta_ndcg\n",
    "                        d2c_qid[j] += lambda_val * (1 - lambda_val) * delta_ndcg\n",
    "            \n",
    "            lambdas[indexes] = lambdas_qid\n",
    "            d2c[indexes] = d2c_qid\n",
    "                           \n",
    "        return lambdas, d2c\n",
    "    \n",
    "    def _update_leafs_with_newton_step(self, tree, X, lambdas, d2c):\n",
    "        leaf_sample_indexes = tree.apply(X)\n",
    "        leafs = np.arange(len(tree.children_left))[tree.children_left == -1]\n",
    "        \n",
    "        for leaf in leafs:\n",
    "            leaf_sample_mask = leaf_sample_indexes == leaf\n",
    "            d2c_sum = d2c[leaf_sample_mask].sum()\n",
    "            \n",
    "            mu = 0\n",
    "            if d2c_sum != 0:\n",
    "                lambda_sum = lambdas[leaf_sample_mask].sum()\n",
    "                mu = lambda_sum / d2c_sum # значение ньютоновского шага для листа\n",
    "            \n",
    "            tree.value[leaf, 0, 0] = mu\n",
    "            \n",
    "    def fit(self, X, y, query_ids, eval_set=None):\n",
    "        y = np.array(y)\n",
    "        query_ids = np.array(query_ids)\n",
    "        unique_qids = np.unique(query_ids)\n",
    "        self.trees = []\n",
    "        scores = np.zeros(len(y))\n",
    "        if eval_set:\n",
    "            eval_scores = np.zeros(len(eval_set[1]))\n",
    "        \n",
    "        for i in tqdm(range(self.n_estimators)):\n",
    "            gc.collect()\n",
    "               \n",
    "            tree = DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth, \n",
    "                splitter=self.splitter, \n",
    "                max_features=self.max_features,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf)\n",
    "            \n",
    "            \n",
    "            lambdas, d2c = self._get_lambdas(y, query_ids, scores)\n",
    "            tree.fit(X, lambdas)\n",
    "            self._update_leafs_with_newton_step(tree.tree_, X, lambdas, d2c)\n",
    "            \n",
    "            self.trees.append(tree)\n",
    "            scores += self.learning_rate * tree.predict(X)\n",
    "    \n",
    "            if eval_set:\n",
    "                eval_scores += self.learning_rate * tree.predict(eval_set[0])\n",
    "            \n",
    "            if i % self.verbose == 0:\n",
    "                if eval_set:\n",
    "                    ndcg_train = ndcg_dataset(scores, y, query_ids)\n",
    "                    ndcg_val = ndcg_dataset(eval_scores, eval_set[1], eval_set[2])\n",
    "                    print(f'Iter: {i}, train NDCG: {ndcg_train:.5f}, val NDCG: {ndcg_val:.5f}, diff: {(ndcg_train - ndcg_val):.5f}')\n",
    "                else:\n",
    "                    print(f'Iter: {i}, train NDCG: {ndcg_dataset(scores, y, query_ids):.5f}')\n",
    "        \n",
    "    def predict(self, X):\n",
    "        scores = np.zeros(len(X))\n",
    "        for i in range(self.n_estimators):\n",
    "            tree = self.trees[i]\n",
    "            scores += self.learning_rate * tree.predict(X)\n",
    "        \n",
    "        return scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_size = int(X.shape[0] * 0.9)\n",
    "lrb = LambdaMartBoosting(n_estimators=2000, \n",
    "                         learning_rate=0.1, \n",
    "                         max_depth=9, verbose=1)\n",
    "eval_set = (X[train_size:], y[train_size:], query_ids[train_size:])\n",
    "lrb.fit(X[:train_size], y[:train_size], query_ids[:train_size], eval_set=eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrb = LambdaMartBoosting(n_estimators=1000, \n",
    "                         learning_rate=0.05, \n",
    "                         max_depth=9)\n",
    "lrb.fit(X, y, query_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse_sub, y_sub, query_ids_sub = load_svmlight_file('data/l2r/test.txt', query_id=True)\n",
    "X_sub = X_sparse_sub.toarray()[:,remove_zero_mask]\n",
    "gc.collect()\n",
    "y_sub = lrb.predict(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submit40.csv', 'w') as f:\n",
    "    f.write('QueryId,DocumentId')\n",
    "    f.write('\\n')\n",
    "    doc_ids = np.arange(1, len(y_sub) + 1)\n",
    "    for qid in np.unique(query_ids_sub):\n",
    "        y_sub_qid = y_sub[query_ids_sub == qid]\n",
    "        doc_ids_qid = doc_ids[query_ids_sub == qid]\n",
    "        indexes_qid = np.argsort(y_sub_qid)[::-1]\n",
    "        doc_ids_qid_ordered = doc_ids_qid.take(indexes_qid)\n",
    "        for doc_id in doc_ids_qid_ordered:\n",
    "            f.write(f'{qid},{doc_id}')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
